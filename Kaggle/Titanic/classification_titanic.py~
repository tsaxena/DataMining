#Required librariesimport pprintimport csvimport numpytry:    import nltk    from nltk.classify.util import apply_features    import string    print "Great!  Looks like you're all set re: NLTK and Python."except Exception, e:    print "Bummer.  Looks like you don't have NLTK and Python set up correctly.  (Exception: "+str(e)+")"    quit()raw_input("\n\nHit enter to get started...")# Reading Data into the file# Training Data needs to be in the format ("features", "class")# Class can be survived/ not survivedprint "Defining Training Data (Reading it from train.csv)"#Load in the csv filecsv_file_object = csv.reader(open('./Data/train.csv', 'rb')) #Skip the fist line as it is a headerheader = csv_file_object.next() known_data_points =[] #Creat a variable called 'data'for row in csv_file_object: #Skip through each row in the csv file    known_data_points.append(row[1:]) #adding each row to the data variableknown_data_points = numpy.array(known_data_points) #Then convert from a list to an arrayraw_input("\n\nHit enter to continue...")#Feature extractor.  Basically takes a sentence/phrase/description/whatever and and outputs a stripped version of it.  This could/should be enhanced (with, eg, stemming), as that would provide easy gains in performance, but this is a good start.  Once you get the basic flow set up for a classification project, you'll spend most of your time in feature extraction.print "Writing Feature Extractor"def feature_extracting_function(data_point):    features = {} #Dictionary, roughly equivalent to a hashtable in other languages.    data_point = ''.join(ch for ch in data_point if ch not in set(string.punctuation)) #Strip punctuation characters from the string. In Python, this happens to be usually done with a .join on the string object, but don't be thrown if you're used to other languages and this looks weird (hell, it looks weird to me), all we're doing is stripping punctuation.    words = data_point.split() #Split data_point on whitespace, return as list    words = [word.lower() for word in words] #Convert all words in list to lowercase.  The [] syntax is a Python "list comprehension"; Google that phrase if you're confused.    #Create a dictionary of features (True for each feature present, implicit False for absent features).  In this case, features are words, but they could be bigger or smaller, simpler or more complex.    for word in words:        features["contains_word_(%s)" % word] = True    return featuresraw_input("\n\nHit enter to continue...")print "Extracting Features from Training Set"train_set = apply_features(feature_extracting_function, known_data_points)pp = pprint.PrettyPrinter(indent=4)pprint.pprint(train_set)raw_input("\n\nHit enter to continue...")print "Gathering unknown data points (new data) to predict on (again, hand-coded, see script source)"#Our query chocolate bars: we want to know whether or not they're matchesunknown_1 = "milky light sweet nutty"unknown_2 = "dark bitter plain"unknown_3 = "dark dark bitter beyond belief organic"unknown_4 = "organic minty sweet dark"raw_input("\n\nHit enter to continue...")#Train a Naive Bayes Classifier (simple but surprisingly effective).  This isn't the only classifier one could use (dtree is another, and there are many, many more), but it's a good start.print "Training Naive Bayes Classifier"