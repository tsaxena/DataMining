
import csv
import numpy
import pandas as pd
import math
import matplotlib.pylab as plt
from scipy import stats
from datetime import datetime
from sklearn.naive_bayes import GaussianNB


class TitanicClassifier(object):
  
    def __init__(self):
	print("Initializing the Classifier")
    	#read the titanic train data    
        trainpath 	= './Data/train.csv'
        testpath  	= './Data/test.csv'
        rawtraindf   	= pd.read_csv(trainpath)
        rawtestdf    	= pd.read_csv(testpath)
	self.traindf   	= self.cleandf(rawtraindf)
        self.testdf    	= self.cleandf(rawtestdf)  
        self.prio       = {}
        self.means 	= {}
	self.ssd 	= {}
	self.totals 	= 0
        self.klasses = [0, 1]
        self.train_features = []
        self.test_features  = []

    #processing each column
    def cleandf(self, df): 
        #print("Clean the data")


	#print("Cleaning the fare data")
	# replace the 0 fares with the mean fare of the class
	# replace 0 with non a number
        # find the mean for the class 
	# replace all nan with the mean class fare
	df.Fare = df.Fare.map(lambda x: numpy.nan if x==0 else x)
	classmeans = df.pivot_table(values='Fare', rows='Pclass', aggfunc=numpy.mean)
        # incredibly useful function
        # get the Fare and Pclass projection
        # applies row-wise to the projection
	df.Fare = df[['Fare', 'Pclass']].apply(lambda x: classmeans[x['Pclass']] if numpy.isnan(x['Fare']) else x['Fare'], axis=1 )

        #print("Cleaning the age data")
	df.Age = df.Age.map(lambda x: numpy.nan if x==0 else x)
	meanAge  = numpy.mean(df.Age)
    	df.Age   = df.Age.map(lambda x: meanAge if numpy.isnan(x) else x)

        #print("Cleaning the embarkment data")
    	modeEmbarked = stats.mode(df.Embarked)[0][0]
        df.embarked = df.Embarked.fillna(modeEmbarked)

	#print("Cleaning the Cabin data")
	df.Cabin = df.Cabin.fillna('Unknown')

	#print("Clean family data")
	#print(df['Ticket'])

        return df
    
	

    def train(self):
	print("Training the Classifier")
	#train features
	trainfeatures = self.traindf[['Pclass','Sex', 'Age','SibSp','Parch','Fare','Cabin','Embarked' ]] 
	trainlabels   = self.traindf[['Survived']]

        # calculate totals for both class
        self.totals = self.traindf.groupby('Survived').size()
	
        #calculate probability
	total = self.traindf.count()
        self.prio   = self.totals.map(lambda x: (x * 1.0)/total)   numeric_features = self.traindf
	print(self.prio)
	print(total)
	
	#for numeric features
        numeric_features = self.traindf[[ 'Survived','Age','SibSp','Parch','Fare']]  
       
        self.means = numeric_features.groupby('Survived').mean()
       
        #grouped.aggregate(numpy.sum)
        self.ssd = numeric_features.groupby('Survived').std()
        print(self.means)
        #print(self.ssd)	

	#for categorical features
        category_features = self.traindf[['Survived','Pclass','Sex', 'Embarked' ]] 
        self.category_feature_names = category_features.columns.values.tolist()
        
        group_by_gender = category_features.groupby(['Survived', 'Sex']).size()
        print(group_by_gender)
        group_by_pclass = category_features.groupby(['Survived', 'Pclass']).size()
        print(group_by_pclass)
        group_by_embark = category_features.groupby(['Survived', 'Embarked']).size()
        print(group_by_embark)
    
    def pdf(self, mean, ssd, x):
       sqrt2pi = math.sqrt(2 * math.pi)
       #Probability Density Function computing P(x|y)
       #input is the mean, sample standard deviation for all the items in y, and x.
       ePart = math.pow(math.e, -(x - mean)**2/(2*ssd**2))
       prob  = ((1.0 / (sqrt2pi*ssd)) * ePart)
       return prob
    

    def calculate(self, x):
       
	#is this the row
        #print(x)
        
        #categorical data 
        #categorialFeatures = list(my_dataframe.columns.values)
        #for cf in categorialFeatures: 
        #     print(x.cf)
	
         
        #for numeric features
        #'Age','SibSp','Parch','Fare']]
        prob = {}  
        for k in self.klasses:
            prob.setdefault(k, 0)
	    print('class name', k)
            for nf in self.numeric_feature_names:
		 
                print(nf)
                #prob[k] += self.pdf(self.means.iloc[k][nf], self.ssd.iloc[k][nf], x.nf)
        #print(probAge)
        #probSibSp = self.pdf(self.means[0]['SibSp'], self.ssd[0]['SibSp'], x.SibSp) 
        #probParch = self.pdf(self.means[0]['Parch'], self.ssd[0]['Parch'], x.Parch) 
        #probFare  = self.pdf(self.means[0]['Fare'], self.ssd[0]['Fare'], x.Fare)  
        # return the category with the highest probability
        #print(results)
       
        return -1 #max of the probabilities of the classes

    def predict(self):
        #prepare the file 
        print("Predicting test data")
	predictiondf = pd.DataFrame(self.testdf['PassengerId'])
        predictiondf['Survived']=[0 for x in range(len(self.testdf))]
        predictiondf.to_csv('./Data/prediction.csv', index=False)

	#find the probability for each class
        predictiondf['Survived'] = self.testdf.apply(lambda row: self.calculate(row), axis=1)
 
        #write it to the output file
        prediction_path = './Data/prediction.csv'
        prediction_csv  = pd.read_csv(prediction_path)
        prediction_csv['Survived']=predictiondf['Survived']
        prediction_csv.to_csv('./Data/first_submission.csv', index =False)



def main():
    print("Calling Naive Bayes")
    c = TitanicClassifier()
    c.train()
    c.predict()
    


if  __name__ =='__main__':
    main()



